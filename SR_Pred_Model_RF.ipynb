{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6585da14",
   "metadata": {},
   "source": [
    "<b>Import Libraries<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59af6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69593b90",
   "metadata": {},
   "source": [
    "<b>import data and handle missing values<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smote_train.csv')\n",
    "df_target = df['historical_data']\n",
    "df_feat = df.drop(['Unnamed: 0','historical_data'],axis=1)\n",
    "df_feat[['column_1','column_2','column_3']] = df_feat[['column_1','column_2','column_3']].fillna(\"NULL\").copy()\n",
    "df_feat = df_feat.fillna(0).copy()\n",
    "\n",
    "#check that all null values are handled\n",
    "sns.heatmap(df_feat.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e241c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummy variables for categorical features\n",
    "df_feat2 = pd.get_dummies(df_feat,columns=['column_1','column_2','column_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd941175",
   "metadata": {},
   "source": [
    "<b>train/test split<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25099807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feat2, df_target, test_size=0.20, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0ffe5",
   "metadata": {},
   "source": [
    "<b>create, train, and evaluate basic model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 500)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdc949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883646a",
   "metadata": {},
   "source": [
    "<b>Find stable range of trees for later use in hyperparameter tuning<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for tree in rfc.estimators_:\n",
    "    predictions.append(tree.predict_proba(X_test)[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7592482",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.vstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_mean = np.cumsum(predictions, axis=0)/np.arange(1, predictions.shape[0] + 1)[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bfc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = []\n",
    "for pred in cum_mean:\n",
    "    scores.append(accuracy_score(y_test, np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d37c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(scores, linewidth=3)\n",
    "plt.xlabel('num_trees')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b82a57",
   "metadata": {},
   "source": [
    "<b> Evaluate feature importances and drop useless ones <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features\n",
    "feature_list = list(df_feat2.columns)\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rfc.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27012601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset style \n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f265eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "\n",
    "# Make a line graph\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_importance = pd.DataFrame(feature_importances,columns=['Name','Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6522fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_importance['Name'].head(26).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp = X_train[['feature_1',\n",
    "'feature_2',\n",
    "'feature_3',\n",
    "'feature_4',\n",
    "'feature_5',\n",
    "'feature_6',\n",
    "'feature_7',\n",
    "'feature_8',\n",
    "'feature_9',\n",
    "'feature_10',\n",
    "'feature_11',\n",
    "'feature_12',\n",
    "'feature_13',\n",
    "'feature_14',\n",
    "'feature_15',\n",
    "'feature_16',\n",
    "'feature_17',\n",
    "'feature_18',\n",
    "'feature_19',\n",
    "'feature_20',\n",
    "'feature_21',\n",
    "'feature_22',\n",
    "'feature_23',\n",
    "'feature_24',\n",
    "'feature_25',\n",
    "'feature_26'\n",
    "]]\n",
    "\n",
    "X_test_imp = X_test[['feature_1',\n",
    "'feature_2',\n",
    "'feature_3',\n",
    "'feature_4',\n",
    "'feature_5',\n",
    "'feature_6',\n",
    "'feature_7',\n",
    "'feature_8',\n",
    "'feature_9',\n",
    "'feature_10',\n",
    "'feature_11',\n",
    "'feature_12',\n",
    "'feature_13',\n",
    "'feature_14',\n",
    "'feature_15',\n",
    "'feature_16',\n",
    "'feature_17',\n",
    "'feature_18',\n",
    "'feature_19',\n",
    "'feature_20',\n",
    "'feature_21',\n",
    "'feature_22',\n",
    "'feature_23',\n",
    "'feature_24',\n",
    "'feature_25',\n",
    "'feature_26'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0b0d8a",
   "metadata": {},
   "source": [
    "<b> Create randomized grid for hyperparamater tuning and choose best model <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36649fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d86f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select model with best paramaters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433fb1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "best_random = rf_random.best_estimator_\n",
    "random_predictions = best_random.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, random_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc19f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(confusion_matrix(y_test,random_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall/precision metrics\n",
    "print(classification_report(y_test,random_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb8b54",
   "metadata": {},
   "source": [
    "<b> Make predictions on test set using trained model from randomized grid search <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_norm.csv')\n",
    "df_feat_test = df_test.drop(['Unnamed: 0'],axis=1)\n",
    "df_feat_test[['column_1','column_2','column_3']] = df_feat_test[['column_1','column_2','column_3']].fillna(\"NULL\").copy()\n",
    "df_feat_test = df_feat_test.fillna(0).copy()\n",
    "\n",
    "#check that all null values are handled\n",
    "sns.heatmap(df_feat_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_test2 = pd.get_dummies(df_feat_test,columns=['column_1','column_2','column_3'])\n",
    "df_feat_test3 = df_feat_test2[['feature_1',\n",
    "'feature_2',\n",
    "'feature_3',\n",
    "'feature_4',\n",
    "'feature_5',\n",
    "'feature_6',\n",
    "'feature_7',\n",
    "'feature_8',\n",
    "'feature_9',\n",
    "'feature_10',\n",
    "'feature_11',\n",
    "'feature_12',\n",
    "'feature_13',\n",
    "'feature_14',\n",
    "'feature_15',\n",
    "'feature_16',\n",
    "'feature_17',\n",
    "'feature_18',\n",
    "'feature_19',\n",
    "'feature_20',\n",
    "'feature_21',\n",
    "'feature_22',\n",
    "'feature_23',\n",
    "'feature_24',\n",
    "'feature_25',\n",
    "'feature_26'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_random.predict(df_feat_test3)\n",
    "test_proba = best_random.predict_proba(df_feat_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(test_predictions)\n",
    "df_proba = pd.DataFrame(test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.concat([df_test,df_pred,df_proba],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.to_excel('YYYYMMDD RF SMOTE Holiday SR Predictions.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
